# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l1Fy-CMwlR0nOnzjcm8VCa3Vsclzb_pi

This file only runs the best algorithms from Supervised learning and Semi Supervised Learning.
"""

# from google.colab import drive
# drive.mount('/content/drive')
import pickle
import numpy as np
from tabulate import tabulate
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

X_test_final=np.loadtxt('\data\Test_data\X_test_final.csv',delimiter=",")
y_test=np.loadtxt('\data\Test_data\y_test.csv',delimiter=",")



def generate_table(row_data):
    '''
    Function to generate table
    '''
    table_header_test=["Algorithm","Specificity","Sensitivity"]
    rows=[]
    for lists in row_data:
        rows.append(lists)

    all_data=rows
    print(tabulate(all_data,headers=table_header_test,tablefmt='grid'))

def performance_metrics(y,y_pred):
    '''
    Function to find Sensitivity, Specificity and Accuracy given the target label and predicted label
    
    Parameters:
    y- target label
    y_pred- predicted label

    Return:
    Specificity,Sensitivity,Accuracy scores
    '''
    
    conf=confusion_matrix(y, y_pred, labels = [0, 1])
    colormap = sns.color_palette("Greens")
    plt.figure(figsize=(6,6))  
    sns.heatmap(conf, annot=True, fmt='g', cmap=colormap)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()
    
    tn, fp, fn, tp = conf[0][0],conf[0][1],conf[1][0],conf[1][1]
    specificity = (tn / (tn+fp)).round(2)
    sensitivity=(tp/(tp+fn)).round(2)
    return [specificity,sensitivity]

def test_model(best_model,X_test,y_test,threshold):
    '''
    Function to find the predicted labels on test set given a trained model
    
    Parameters:
    best_model- target label
    X_test,y_test- predicted label
    threshold- cut off threshold for probability

    Return:
    List of performance metrics Specificity,Sensitivity,Accuracy scores
    '''

    y_hat=best_model.predict_proba(X_test)
    y_pred = np.zeros(len(y_hat))
    for i in range(len(y_hat)):
      if y_hat[i, 1] > threshold:
        y_pred[i] = 1
      else:
        y_pred[i] = 0
        y_pred = y_pred.astype(int)

    return performance_metrics(y_test,y_pred)

best_sl_model=pickle.load(open('/models/supervised_models/best_dec_tree_model.pkl', 'rb'))
best_ssl_model=pickle.load(open('/models/semi_supervised_models/best_label_prop_model_exptb.pkl', 'rb'))

"""# Decision Tree Classifier"""

result_sl=test_model(best_sl_model,X_test_final,y_test,0.2)

result_sl=['Decision Tree Classifier']+result_sl

"""# *Label Propagation (using 40% data)*"""

result_ssl=test_model(best_ssl_model,X_test_final,y_test,0.2)

result_ssl=['Label Propagation']+result_ssl

"""# RESULTS"""

print('Performance of Algorithms on Testing Data:')
sl_test_data=[result_sl,result_ssl]
generate_table(sl_test_data)